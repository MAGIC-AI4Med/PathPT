{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "1. Install dependencies (with jupyter notebook, not mentioned in the requirements.txt, to run this file).\n",
    "2. Download model [KEEP](https://huggingface.co/Astaxanthin/KEEP) and place it in `./base_models/`\n",
    "3. Download pre-extracted TCGA-UCS [features](https://drive.google.com/file/d/1RNSIINkumfhiyqwL82hUXALCtdyPhbC3/view?usp=sharing) and place them in `./features/keep/ucs/h5_files/`\n",
    "4. Download an example experiment result [folder](https://drive.google.com/file/d/1Cvkv2Vsw9_aQ6GCRkndiAeMjyK-CWA8v/view?usp=sharing) containing learned prompt and spatial aware module weights and place it in `./fewshot_results`\n",
    "5. Download an example slide:TCGA-N8-A4PN-01Z-00-DX1.92336FBA-79D1-49F9-BC2A-7C7BF4147E07.svs from [GDC](https://portal.gdc.cancer.gov/analysis_page?app=Downloads) or this [link](https://drive.google.com/file/d/1VpRrOEFJeio_rvh21lFn_SSph9GZdoE5/view?usp=sharing) and place it in `./` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import h5py\n",
    "import json\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report, confusion_matrix\n",
    "import params\n",
    "\n",
    "# foudantion model specific\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from subtyping.main_wsi_subtyping_KEEP import model_init\n",
    "from models.PathPT_model_KEEP import OriginKEEP, CustomKEEP, PPTKEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load your foundation model\n",
    "keep_model_path = './base_models/keep'\n",
    "device = 'cuda:0'\n",
    "keep_model = AutoModel.from_pretrained(keep_model_path, trust_remote_code=True)\n",
    "keep_tokenizer = AutoTokenizer.from_pretrained(keep_model_path, trust_remote_code=True)\n",
    "keep_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "\n",
    "# make a config for model init and inference\n",
    "dataset_name = 'ucs'\n",
    "cfg = params.PromptLearnerConfig(input_size=256)\n",
    "param = params.subtype_params[dataset_name]\n",
    "param['lr'] = 1e-4 # not used in inference\n",
    "param['epochs'] = 20 # not used in inference\n",
    "\n",
    "# load subtypes and prompts for zeroshot and fewshot init\n",
    "with open(params.DATASET_DIVISION, 'r') as f:\n",
    "    meta = json.load(f)[dataset_name.upper()]\n",
    "name2label = meta['name2label']\n",
    "subtype_classnames = sorted(name2label.keys(), key=lambda x: name2label[x])\n",
    "subtype_classnames = ['Normal'] + subtype_classnames\n",
    "print(subtype_classnames)\n",
    "zeroshot_prompt_lst,classnames_list = utils.load_prompts(dataset_name, subtype_classnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load zeroshot model\n",
    "zeroshot_prompt = []\n",
    "for cls_prompt in zeroshot_prompt_lst:\n",
    "    index = random.randint(0, len(cls_prompt) - 1)\n",
    "    zeroshot_prompt.append(cls_prompt[index])\n",
    "zero_shot_model = OriginKEEP(zeroshot_prompt, keep_model, keep_tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pathpt model\n",
    "\n",
    "# init model\n",
    "pathpt_model, _, _ = model_init(cfg, classnames_list, keep_model, keep_tokenizer, device, param, vfeat_dim = 768)\n",
    "\n",
    "# load learned prompts\n",
    "learned_prompt_pt = './fewshot_results/pathpt_KEEP_10shot_ucs_Nov10-20-11-09-037/fold5/prompt_embedding.pt'\n",
    "learned_prompt = torch.load(learned_prompt_pt, map_location=device)\n",
    "with torch.no_grad():\n",
    "    pathpt_model.prompt_learner.ctx.copy_(learned_prompt)\n",
    "\n",
    "# load spatial aware module\n",
    "spatial_aware_module_pt = './fewshot_results/pathpt_KEEP_10shot_ucs_Nov10-20-11-09-037/fold5/spatial_aware_module.pt'\n",
    "spatial_aware_module = torch.load(spatial_aware_module_pt, map_location=device)\n",
    "pathpt_model.mlp.load_state_dict(spatial_aware_module)\n",
    "\n",
    "pathpt_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load example wsi feature (frozen visual feature, .h5 format)\n",
    "feature_h5 = './features/keep/ucs/h5_files/TCGA-N8-A4PN-01Z-00-DX1.92336FBA-79D1-49F9-BC2A-7C7BF4147E07.h5'\n",
    "with h5py.File(feature_h5, 'r') as f:\n",
    "    visual_feat = f['features'][:]\n",
    "    coords = f['coords'][:]\n",
    "    labels = f['labels'][:]\n",
    "visual_feat = torch.from_numpy(visual_feat).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zeroshot inference\n",
    "\n",
    "# logits of all patches, shape: (num_patches, num_classes)\n",
    "with torch.no_grad():\n",
    "    logits_zeroshot = zero_shot_model(visual_feat)\n",
    "\n",
    "# predicted class of all patches, shape: (num_patches,)\n",
    "patch_result_zeroshot = torch.argmax(logits_zeroshot, dim=1)\n",
    "\n",
    "# exclude normal class 0 (we assume all WSIs in subtyping task are neoplastic)\n",
    "patch_count_zeroshot = torch.bincount(patch_result_zeroshot, minlength=len(subtype_classnames))[1:]\n",
    "pred_label_zeroshot = torch.argmax(patch_count_zeroshot).item() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathpt 10-shot inference\n",
    "\n",
    "# logits of all patches, shape: (num_patches, num_classes)\n",
    "with torch.no_grad():\n",
    "    _, logits = pathpt_model(visual_feat)\n",
    "\n",
    "# predicted class of all patches, shape: (num_patches,)\n",
    "patch_result = torch.argmax(logits, dim=1)\n",
    "\n",
    "# exclude normal class 0 (we assume all WSIs in subtyping task are neoplastic)\n",
    "patch_count = torch.bincount(patch_result, minlength=len(subtype_classnames))[1:]\n",
    "pred_label = torch.argmax(patch_count).item() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "gt_count = np.bincount(labels, minlength=len(subtype_classnames))[1:]\n",
    "gt_label = np.argmax(gt_count) + 1\n",
    "print('ground truth:', subtype_classnames[gt_label])\n",
    "print('zeroshot_result:', subtype_classnames[pred_label_zeroshot])\n",
    "print('pathpt_result:', subtype_classnames[pred_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import openslide\n",
    "\n",
    "with h5py.File(feature_h5, 'r') as f:\n",
    "    coords = f['coords'][:] \n",
    "    labels_np = f['labels'][:]\n",
    "\n",
    "wsi_path = './TCGA-N8-A4PN-01Z-00-DX1.92336FBA-79D1-49F9-BC2A-7C7BF4147E07.svs'\n",
    "assert os.path.exists(wsi_path), f'WSI not found: {wsi_path}'\n",
    "slide = openslide.OpenSlide(wsi_path)\n",
    "\n",
    "thumb_level = 3\n",
    "assert thumb_level < slide.level_count, f\"thumb_level={thumb_level} >= level_count={slide.level_count}\"\n",
    "\n",
    "thumb_w, thumb_h = slide.level_dimensions[thumb_level]\n",
    "downsample = slide.level_downsamples[thumb_level]\n",
    "downsample = float(downsample)\n",
    "\n",
    "thumbnail = slide.read_region((0, 0), thumb_level, (thumb_w, thumb_h)).convert('RGB')\n",
    "\n",
    "patch_size_lvl0 = 448\n",
    "coords_thumb = (coords / downsample).astype(np.int32)\n",
    "patch_size_thumb = max(1, int(round(patch_size_lvl0 / downsample)))\n",
    "\n",
    "H, W = thumbnail.size[1], thumbnail.size[0]\n",
    "mask_gt = np.zeros((H, W), dtype=np.int16)\n",
    "mask_zeroshot = np.zeros((H, W), dtype=np.int16)\n",
    "mask_pathpt = np.zeros((H, W), dtype=np.int16)\n",
    "\n",
    "if isinstance(patch_result_zeroshot, torch.Tensor):\n",
    "    patch_result_zeroshot_np = patch_result_zeroshot.detach().cpu().numpy().astype(np.int16)\n",
    "else:\n",
    "    patch_result_zeroshot_np = patch_result_zeroshot.astype(np.int16)\n",
    "\n",
    "if isinstance(patch_result, torch.Tensor):\n",
    "    patch_result_np = patch_result.detach().cpu().numpy().astype(np.int16)\n",
    "else:\n",
    "    patch_result_np = patch_result.astype(np.int16)\n",
    "\n",
    "labels_np = labels_np.astype(np.int16)\n",
    "\n",
    "def paint_mask(mask, coords_thumb, patch_size_thumb, patch_labels):\n",
    "    H, W = mask.shape\n",
    "    ps = patch_size_thumb\n",
    "    for (x_t, y_t), lab in zip(coords_thumb, patch_labels):\n",
    "        x0 = int(x_t)\n",
    "        y0 = int(y_t)\n",
    "        x1 = x0 + ps\n",
    "        y1 = y0 + ps\n",
    "        if x0 >= W or y0 >= H or x1 <= 0 or y1 <= 0:\n",
    "            continue\n",
    "        x0c = max(0, x0)\n",
    "        y0c = max(0, y0)\n",
    "        x1c = min(W, x1)\n",
    "        y1c = min(H, y1)\n",
    "        mask[y0c:y1c, x0c:x1c] = lab\n",
    "\n",
    "paint_mask(mask_gt, coords_thumb, patch_size_thumb, labels_np)\n",
    "paint_mask(mask_zeroshot, coords_thumb, patch_size_thumb, patch_result_zeroshot_np)\n",
    "paint_mask(mask_pathpt, coords_thumb, patch_size_thumb, patch_result_np)\n",
    "\n",
    "num_classes = len(subtype_classnames)\n",
    "palette = np.vstack([\n",
    "    np.array([0, 0, 0]),\n",
    "    np.array([ 31, 119, 180]),\n",
    "    np.array([255, 127,  14]),\n",
    "    np.array([ 44, 160,  44]),\n",
    "    np.array([214,  39,  40]),\n",
    "    np.array([148, 103, 189]),\n",
    "    np.array([140,  86,  75]),\n",
    "    np.array([227, 119, 194]),\n",
    "    np.array([127, 127, 127]),\n",
    "    np.array([188, 189,  34]),\n",
    "    np.array([ 23, 190, 207]),\n",
    "])\n",
    "if num_classes > palette.shape[0]:\n",
    "    extra = np.random.randint(0, 256, size=(num_classes - palette.shape[0], 3))\n",
    "    palette = np.vstack([palette, extra])\n",
    "palette = (palette[:num_classes] / 255.0)\n",
    "\n",
    "def mask_to_color(mask, palette):\n",
    "    H, W = mask.shape\n",
    "    color = np.zeros((H, W, 3), dtype=np.float32)\n",
    "    for cls_idx in range(len(palette)):\n",
    "        sel = (mask == cls_idx)\n",
    "        if np.any(sel):\n",
    "            color[sel] = palette[cls_idx]\n",
    "    return color  # float32 in [0,1]\n",
    "\n",
    "color_gt = mask_to_color(mask_gt, palette)\n",
    "color_zeroshot = mask_to_color(mask_zeroshot, palette)\n",
    "color_pathpt = mask_to_color(mask_pathpt, palette)\n",
    "thumb_np = np.array(thumbnail).astype(np.float32) / 255.0\n",
    "alpha = 0.45\n",
    "alpha_gt = (mask_gt != 0).astype(np.float32) * alpha\n",
    "alpha_zeroshot = (mask_zeroshot != 0).astype(np.float32) * alpha\n",
    "alpha_pathpt = (mask_pathpt != 0).astype(np.float32) * alpha\n",
    "\n",
    "def overlay(base, color, alpha_map):\n",
    "    # base, color: (H, W, 3), in [0,1]; alpha_map: (H, W) in [0,1]\n",
    "    out = base.copy()\n",
    "    a = alpha_map[..., None]\n",
    "    out = out * (1 - a) + color * a\n",
    "    return out\n",
    "\n",
    "overlay_gt = overlay(thumb_np, color_gt, alpha_gt)\n",
    "overlay_zeroshot = overlay(thumb_np, color_zeroshot, alpha_zeroshot)\n",
    "overlay_pathpt = overlay(thumb_np, color_pathpt, alpha_pathpt)\n",
    "\n",
    "plt.figure(figsize=(10, 20))\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.imshow(thumb_np)\n",
    "plt.axis('off')\n",
    "plt.title('WSI thumbnail (level {})'.format(thumb_level))\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.imshow(overlay_gt)\n",
    "plt.axis('off')\n",
    "plt.title('Ground Truth mask overlay (coarse mask)')\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.imshow(overlay_zeroshot)\n",
    "plt.axis('off')\n",
    "plt.title('Zero-shot mask overlay')\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.imshow(overlay_pathpt)\n",
    "plt.axis('off')\n",
    "plt.title('PathPT 10-shot mask overlay')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example for reproduction: pathpt-10shot-KEEP inference for TCGA-UCS fold5\n",
    "\n",
    "# load test data info\n",
    "slide_data = pd.read_csv('./multifold/dataset_csv_10shot/TCGA/UCS/fold5.csv', dtype={'train': str, 'val': str, 'test': str})\n",
    "data = slide_data.loc[:, 'test'].dropna()\n",
    "label = slide_data.loc[:, 'test_label'].dropna()\n",
    "\n",
    "# inference on all test slides\n",
    "pred_labels = []\n",
    "gt_labels = []\n",
    "for i in range(len(data)):\n",
    "    slide_name = data.iloc[i]\n",
    "    feature_h5 = os.path.join('./features/keep/ucs/h5_files', slide_name + '.h5')\n",
    "\n",
    "    with h5py.File(feature_h5, 'r') as f:\n",
    "        visual_feat = f['features'][:]\n",
    "    visual_feat = torch.from_numpy(visual_feat).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, logits = pathpt_model(visual_feat)\n",
    "        \n",
    "    patch_result = torch.argmax(logits, dim=1)\n",
    "    patch_count = torch.bincount(patch_result, minlength=len(subtype_classnames))[1:]\n",
    "    pred_label = torch.argmax(patch_count).item() + 1\n",
    "    gt_label = label.iloc[i] + 1\n",
    "    pred_labels.append(pred_label)\n",
    "    gt_labels.append(gt_label)\n",
    "    \n",
    "    print(f'Slide: {slide_name}, Predicted: {subtype_classnames[pred_label]}, Ground Truth: {subtype_classnames[gt_label]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n",
    "bacc = balanced_accuracy_score(gt_labels, pred_labels)\n",
    "report = classification_report(gt_labels, pred_labels, output_dict=True, zero_division=0)\n",
    "wf1 = report['weighted avg']['f1-score']\n",
    "print(f'Balanced Acc: {bacc:.4f}, Weighted F1: {wf1:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transmil2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
